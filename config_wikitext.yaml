# Model configuration
model_name: 'distilgpt2'  # or any other small language model from HuggingFace
dataset_name: 'wikitext'  # WikiText-2 dataset
dataset_config: 'wikitext-2-raw-v1'  # Raw version of WikiText-2
text_column: 'text'  # column name containing the text in your dataset

# Training configuration
output_dir: './results_wikitext'
num_epochs: 3
batch_size: 8
learning_rate: 0.00002
max_length: 128