# Model configuration
model_name: 'distilgpt2'  # or any other small language model from HuggingFace
dataset_name: 'wikitext-2-v1'  # smaller dataset for faster testing
text_column: 'text'  # column name containing the text in your dataset

# Training configuration
output_dir: './results'
num_epochs: 3
batch_size: 8
learning_rate: 2e-5
max_length: 128